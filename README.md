# Обучение модели классификации комментариев

## Задача проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо научить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

У итоговой модели значение метрики качества F1 должно быть не меньше 0.75.

## Инструменты и навыки

`Python`
`Pandas`
`Numpy`
`Pymystem3`
`Scikit-learn`
`Matplotlib`
`BERT`
`nltk`
`tf-idf`

## Краткое описание выполнения проекта

Для запуска нового сервиса интернет-магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 
Подготовленны данные обучения на моделях. Выбран способ баланса классов и поделены данные на обучающую, валидационную и тестовою выборку. Обучены модели и выбраны лучшие из них на валидационной выборке. Показаны параметры качества моделей. 

## Данные и выводы

Исходные данные обладают большим количеством признаков. Созданных столбцов больше, чем записей данных. Так как _TF-IDF_ превращают текст в численные значения, лучшими моделями, прошедшими рубеж F1-метрики в 0.75, стали **LogisticRegression** и **SGDClassifier**.

На тестовой выбоке по метрике _**F1**_ лучше всего себя показал **LogisticRegression** всего на 0.07. Данная модель обладает больними показателями _**Precision**_ и _**Accuracy**_. Это говорит нам, что токсичные комментарии находятся лучше.

**SGDClassifier** показал себя лучше в _**ROC-AUC**_ и _**Recall**_ метриках. Модель способна обработать больше записей.
